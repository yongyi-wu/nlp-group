{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Error_Analysis_711.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9cQjnJNCzkd"
      },
      "source": [
        "# Section 0: Mount Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8-bzcdJCzke"
      },
      "source": [
        "### Note: the notebook will not run unless you have our files in the Google Drive. If you need to run the file, email yilinwan@andrew.cmu.edu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5P32ROaCCzkf",
        "outputId": "8248a1e9-96fe-49f6-cd17-3710db3887e5"
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.flush_and_unmount()\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qlc3aK1Czkg"
      },
      "source": [
        "import os\n",
        "os.chdir(\"drive/MyDrive/nlp-group\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srrS4xglkXml"
      },
      "source": [
        "# Section 2: Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkaZUh_VkanJ"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import json as js\n",
        "import copy as cp"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMaopFH4DY5g"
      },
      "source": [
        "## Load predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYNevVPUDcEb"
      },
      "source": [
        "true = pd.read_csv(\"goemotions/data/test.tsv\", sep='\\t', header=None)\n",
        "true.columns = [\"text\", \"label\", \"label_string\"]\n",
        "pred_base = pd.read_csv(\"experiment/Baseline/Baseline/11-23_05-46_test_prediction.tsv\",\n",
        "                        sep = \"\\t\")\n",
        "pred_new = pd.read_csv(\"out/seed711/12-05_05-51_test_prediction.tsv\",\n",
        "                        sep = \"\\t\")\n",
        "emotions = open(\"goemotions/data/emotions.txt\").read().split(\"\\n\")"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGMO9ORIS_dH"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka4fQNEOs6qV"
      },
      "source": [
        "## compares whether 2 string refers to the same thing\n",
        "def compare_emotions(emo1, emo2):\n",
        "  emo1_split = set(emo1.split(\",\"))\n",
        "  emo2_split = set(emo2.split(\",\"))\n",
        "  if emo1_split == emo2_split: return True\n",
        "  return False\n",
        "\n",
        "def compare_emotions_mult(emo1, emo2):\n",
        "  emo1_split = emo1.split(\",\")\n",
        "  emo2_split = emo2.split(\",\")\n",
        "  if len(emo1_split) == 1:\n",
        "    if emo1_split[0] == emo2_split[0]: return True\n",
        "    return False\n",
        "  for emo in emo1_split:\n",
        "    if emo not in emo2_split: return False\n",
        "  return True\n",
        "\n",
        "## find max N element in an set \n",
        "def maxN(S, N):\n",
        "  max_S = max(S)\n",
        "  if N == 1: \n",
        "      return set([max_S])\n",
        "  S.remove(max_S)\n",
        "  result = set([max_S])\n",
        "  result = set.union(result, maxN(S, N-1))\n",
        "  return result\n",
        "\n",
        "## takes in a mistake dict and outputs the top N most frequent mistakes\n",
        "def top_mistakes(D, N):\n",
        "  counts_dict = dict()\n",
        "  counts = set()\n",
        "  for key in D:\n",
        "    counts_dict[key] = len(D[key])\n",
        "    counts.add(len(D[key]))\n",
        "  result_counts_dict = dict()\n",
        "  result_mistakes_dict = dict()\n",
        "  topNCounts = maxN(counts, N)\n",
        "  for key in D:\n",
        "    if counts_dict[key] in topNCounts:\n",
        "      result_mistakes_dict[key] = D[key]\n",
        "      result_counts_dict[key] = counts_dict[key]\n",
        "  return result_counts_dict, result_mistakes_dict\n",
        "\n",
        "## given an dataframe, retain the top k values of a row and output a new df\n",
        "def pred_topK(df, k):\n",
        "  result = []\n",
        "  for i in range(len(df)):\n",
        "    probs = df.iloc[i, :].values\n",
        "    top_ids = np.argpartition(probs, -k)[-k:]\n",
        "    probs_top = probs[top_ids]\n",
        "    top_ids_ordered = top_ids[np.argsort(-probs_top)]\n",
        "    top_ids_ordered_str = top_ids_ordered.astype(str)\n",
        "    result.append(','.join(top_ids_ordered_str))\n",
        "  return result\n",
        "\n",
        "a = pred_topK(pred_base, 3)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U24X-mRFJp3"
      },
      "source": [
        "## error analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LyEf2rKLUnj"
      },
      "source": [
        "def improved_text(true, pred_base, pred_new, emotions):\n",
        "  ## process the predicted values to retain top 3 emotions:\n",
        "  pred_base_emo = pred_topK(pred_base, 3)\n",
        "  pred_new_emo = pred_topK(pred_new, 3)\n",
        "\n",
        "  ## retain the error columns \n",
        "  pred_base_error_ids = []\n",
        "  pred_new_error_ids = []\n",
        "  for i in range(len(true)):\n",
        "    if not compare_emotions_mult(true.iloc[i, 1], pred_base_emo[i]):\n",
        "      pred_base_error_ids.append(i)\n",
        "    if not compare_emotions_mult(true.iloc[i, 1], pred_new_emo[i]):\n",
        "      pred_new_error_ids.append(i)\n",
        "  #pred_base_error = true.iloc[pred_base_error_ids, :]\n",
        "  #pred_new_error = true.iloc[pred_new_error_ids, :]\n",
        "  unique_base = np.setdiff1d(pred_base_error_ids, pred_new_error_ids)\n",
        "  return unique_base, true.iloc[unique_base, :]\n",
        "      \n",
        "improved_id, improved = improved_text(true, pred_base, pred_new, emotions)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0GIUWVcTDfo"
      },
      "source": [
        "def stat_improved(df, ids, pred_raw):\n",
        "  result = dict()\n",
        "  pred = []\n",
        "  for i in ids:\n",
        "    pred.append(pred_raw[i])\n",
        "  for i in range(len(df)):\n",
        "    mistake_txt = df[\"text\"].values[i]\n",
        "    true_tmp = frozenset(df[\"label\"].values[i].split(\",\"))\n",
        "    pred_keys = pred[i].split(\",\")[0]\n",
        "    pred_tmp = frozenset(pred_keys[0])\n",
        "    key_tmp = (true_tmp, pred_tmp)\n",
        "    #print(pred_tmp)\n",
        "    if key_tmp not in result:\n",
        "      result[key_tmp] = []\n",
        "    result[key_tmp].append(mistake_txt)\n",
        "  return result\n",
        "improved_stat = stat_improved(improved, improved_id.astype(int), pred_topK(pred_base, 3))\n"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x98-igYc_Bm5"
      },
      "source": [
        "## Table 2 in report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njZGQvlH_Kze"
      },
      "source": [
        "Most common mistakes by the baseline model that are correctly classified by our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckFPitiGecoA",
        "outputId": "2079d335-c33c-4149-f1d5-2c01bdcc8d2c"
      },
      "source": [
        "def print_topk_count(improved_stat, k, emotions):\n",
        "  count_dict, text_dict = top_mistakes(improved_stat, k)\n",
        "  for key in count_dict:\n",
        "    true_label = key[0]\n",
        "    pred_label = key[1]\n",
        "    print(\"True Label: \", end=\" \")\n",
        "    for k in true_label:\n",
        "      print(emotions[int(k)], end=\" \")\n",
        "    print(\"  ||  \", end=\" \")\n",
        "    print(\"Pred label: \", end=\" \")\n",
        "    for k in pred_label:\n",
        "      print(emotions[int(k)], end=\" \")\n",
        "    print(\"  ||  \", end=\" \")\n",
        "    print(\"Count: \", end=\" \")\n",
        "    print(count_dict[key])\n",
        "\n",
        "print_topk_count(improved_stat, 7, emotions)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Label:  neutral   ||   Pred label:  approval   ||   Count:  32\n",
            "True Label:  neutral   ||   Pred label:  amusement   ||   Count:  50\n",
            "True Label:  neutral   ||   Pred label:  anger   ||   Count:  36\n",
            "True Label:  neutral   ||   Pred label:  annoyance   ||   Count:  23\n",
            "True Label:  neutral   ||   Pred label:  admiration   ||   Count:  11\n",
            "True Label:  neutral   ||   Pred label:  curiosity   ||   Count:  16\n",
            "True Label:  curiosity   ||   Pred label:  anger   ||   Count:  13\n",
            "True Label:  approval   ||   Pred label:  anger   ||   Count:  11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxOIuvP3_SbM"
      },
      "source": [
        "## Table 3 of report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2w0AWrh_Vkn"
      },
      "source": [
        "Samples that are misclassified by the baseline model and correctly classified by our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O80HoUpTfEjz",
        "outputId": "68c90268-49e2-43d0-9bfb-93777b975471"
      },
      "source": [
        "def print_topk_text(improved_stat, k, emotions):\n",
        "  count_dict, text_dict = top_mistakes(improved_stat, k)\n",
        "  for key in text_dict:\n",
        "    true_label = key[0]\n",
        "    pred_label = key[1]\n",
        "    print(\"True Label: \", end=\" \")\n",
        "    for k in true_label:\n",
        "      print(emotions[int(k)], end=\" \")\n",
        "    print(\"  ||  \", end=\" \")\n",
        "    print(\"Pred label: \", end=\" \")\n",
        "    for k in pred_label:\n",
        "      print(emotions[int(k)], end=\" \")\n",
        "    print(\"  ||  \", end=\" \")\n",
        "    print(\"Count: \", end=\" \")\n",
        "    print(count_dict[key])\n",
        "    for txt in text_dict[key]:\n",
        "      print(txt)\n",
        "    print(\"----------------------------------------------------------------------\")\n",
        "\n",
        "print_topk_text(improved_stat, 7, emotions)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Label:  neutral   ||   Pred label:  approval   ||   Count:  32\n",
            "Hey that's a thought! Maybe we need [NAME] to be the celebrity vaccine endorsement!\n",
            "Well someone posted the ingredients in the comments below. I‚Äôm still new to the whole vegan thing.\n",
            "As a Jeep driver, I constantly have to remind other Jeep drivers that 4WD/AWD only makes a difference when driving. Everyone has 4-wheel stop.\n",
            "Ok google it then. ü§¶üèº‚Äç‚ôÄÔ∏è\n",
            "The complete series is on Hulu just finished watching it. Definitely recommend\n",
            "It really do be like that\n",
            "> Sure it might make the population 4:1 [RELIGION] but it's still an awefully large mibority The population already is 4:1 [RELIGION].\n",
            "Joining the server when everyone's at 1/4hp and out of ammo, with no damage to your...uh...living room. Yeah, ggwp.\n",
            "We‚Äôre a second half team. We got this. COYG!!\n",
            "[NAME] follows me on Instagram so it's ok.\n",
            "Definitely not just on this sub. I keep seeing them on Instagram too.\n",
            "Now this exactly what I came to this sub for\n",
            "Was going to say, that‚Äôs common practice for most women‚Äôs health appointments to help deal with relationship abuse.\n",
            "No, but it changes the expectations that people have for you. You have so deliberately change who you are to play to your target audience.\n",
            "This isn't meant to be a diy thing I think it's a YouTube craft channel they exist because it's calming to watxh\n",
            "I've probably put a couple hundred miles on my space saver tire. It's still on there right now.\n",
            "It was at that moment she decided to go back to college.\n",
            "It's fishphobic!\n",
            "The only one I'd recomend is [NAME] to be honest\n",
            "Yep, she's completely isolated. Part of the abuse.\n",
            "You're easily as classist as her.\n",
            "[NAME] doesn‚Äôt roll his ankle on a üéæ in 2011 and we win a premiership imo\n",
            "And you got it, a federal tax cut. If you want to pay less taxes overall you need to stop electing democrats.\n",
            "As sure as gods got sandals, it sure beats fighting dudes with treasure trails\n",
            "I would have thought so yeah.\n",
            "It's the app, you get daily readings, you can communicate with the other members, reminders, etc, download the app you'll see\n",
            "I'm a [NAME] and tripping has only strengthened my faith. To each their own.\n",
            "It's pretty warm in Australia during this time of year.\n",
            "That's the impression I've always had, but man the owner gets snippy if you disagree on your review!\n",
            "I don't always do this, but when I do, I'm listening to the unedited version of \"Killing In The Name Of\".\n",
            "Nope, works just fine. Was just there.\n",
            "The entire culture of NE is win at all costs. Not sure where you live but if that kid shovels snow..tell mom to him bring home .\n",
            "----------------------------------------------------------------------\n",
            "True Label:  neutral   ||   Pred label:  amusement   ||   Count:  50\n",
            "I think the fan base is mostly past that at this point. Almost everyone has MASSIVE problems with some of the decisions Nintendo makes.\n",
            "Unfortunately for us it‚Äôs not too early. But if you want way too early 2020 draft discussion I‚Äôm really high on [NAME] from Wisconsin\n",
            "Not journalists...media activists.\n",
            "yep, you don't hate Mondays, you hate capitalism. \n",
            "[NAME] can‚Äôt hurt us anymore.\n",
            "Maybe it‚Äôs flaccid and shaking it makes sense when you‚Äôre being put under in the comments. loool read a few pounds.\n",
            "> no money at what normal, un-secterian people want! Surely not being sectarian should be considered normal in a civilised democratic society\n",
            "It WaSn'T TrUe CoMuNiSm !!!!! Derp It WaS StAtE CaPiTaLiSm!!! /s\n",
            "He's not interested, blessim...\n",
            "then never drive because the person in the other lane could swerve over and kill you\n",
            "Welcome to religion 101\n",
            "Says the guy not replying to any counter points lmao\n",
            "Parliament won't let a hard brexit go through, there are far too few MPs who would accept it.\n",
            "I listened to this song the other day for the first time and... oh boy yeah\n",
            "No one drinks Old Style\n",
            "His sister likes his Cox\n",
            "GINO!!!\n",
            "‚ÄúI couldn‚Äôt, I wouldn‚Äôt‚Äù you said it ;)\n",
            "Nor are they common in the UK. Never seen one in the middle.\n",
            "My favourite is peeing in restrooms and your feet can't touch the floor while sitting on the toilet.\n",
            "Oh, I don‚Äôt work there. My bf is in a band that plays there often. \n",
            "I DO NOT NEGOTIATE WITH TERRORISTS this is what I tell my 3.5 year old on the daily\n",
            "The frequency with which I hear ‚Äúgone overseas to defend our country‚Äù without a hint of irony should be criminal in itself\n",
            "People who don‚Äôt want to own houses\n",
            "I‚Äôve never seen such dramatic tongue involvement.\n",
            "[NAME] doesn't believe in tipping.\n",
            "Dude your source on the school says they would investigate. Not a condemnation. Not in any stretch.\n",
            "Luckily for her former therapist maybe she can no longer leave her home.\n",
            "bushwick, and playing a drum doesn't mean someone cannot work a job. \n",
            "None. If you get anything at all, it's a bonus, but don't expect anything.\n",
            "Those are sexist theories not facts.\n",
            "Oh no way is it miners, it's blockstream fault they bought every developer that had commit access to bitcoin's repository. End of story.\n",
            "Weird flex but ok\n",
            "Some people are just very special lmao\n",
            "The god of metal does not approve\n",
            "I mean, this just looks more like a case of a guy being overrated coming out of high school.\n",
            "Because there's such a thing as \"too good to be true\" and some people are still skeptical of that.\n",
            "Kinda both, they maintain a pin-up section in their newspaper bizarrely enough. Not like any of the credible newspapers in the province ever needed that.\n",
            "All women are useless - maybe if you made better choices it would be better for ya\n",
            "I went skiing in another state and ran into a gaggle of students. Distance guarantees nothing.\n",
            "This made [NAME] [NAME] verrrrrrry famous this year. She was always famous but this year her sounds and food descriptions won her the top award!\n",
            "*Duck Tales! whooh ooh* *Every day they're out there making* *Duck Tales! whooh ooh* *Tales of daring do bad and good luck tales! whooh ooh*\n",
            "Most rapists aren't, unfortunately. \n",
            "Nah, I it was cool to be a pedo back in the old days, ask [NAME] \n",
            "I know it's Nightengale but he's saying upwards of 12/350.. ya no thanks.\n",
            "Yours is censored though.\n",
            "In the voice of [NAME] from The Office \"Incorrect. You didn't *Pin* anyone\"\n",
            "It is though, you just want that to be false.\n",
            "Oh look, they‚Äôre little footballs!\n",
            "Had to watch \"Elmo in Grouchland\" one time too many when my kids were little...musical Elmo / Oscar overdose...\n",
            "----------------------------------------------------------------------\n",
            "True Label:  neutral   ||   Pred label:  anger   ||   Count:  36\n",
            "And some of us wish to die first so we don't have to deal with the loneliness.\n",
            "Oh boy ü§£ü§£\n",
            "Yes, oops \n",
            "Not sad enough fo here the skeleton is dead so he can't comit sucide\n",
            "Turns out they weren't wrong about [NAME] either\n",
            "Maybe she'll finish Wardenclyffe Tower and stop Slappy and his monsters!\n",
            "Apologize to [NAME]\n",
            "THE PACK RUNS DEEP AND HARD. I WOULD SHARE MY KRAFT MAC AND CHEESE WITH YOU ANY DAY. AROOOOOOOOO\n",
            "Laxatives in brownies. Itching powder in shoes. Remove toilet paper from bathroom. Kill him Sharpie his face when he goes to sleep Put a stink bomb in his booksack Steal his girl.\n",
            "Your hairline is further away than [NAME] hope of gaining subscribers while still having beef with you.\n",
            "If a greedy and powerful few can make a buck they will.\n",
            "[NAME] career ended after he broke his foot when he kicked a seat while blacked out on a party after a Vikings game.\n",
            "Waiting to see angry ‚Äúpedos‚Äù or whatever they call themselves thinking this is fact and melting down over at t_d\n",
            "oh gosh [NAME] had issues as well with someone and his leg i forgot.\n",
            "If the answer is No, the kid dies. If the answer is yes, the kid also dies\n",
            "You're in the wrong subs\n",
            "I believe it was the \"Master Batters.\"\n",
            "I clearly recall being told the same thing in ‚Äò97, when I was driving a ‚Äò74...except the years were different obv.\n",
            "Oh well that's that then :)\n",
            "Oh and I forgot to add: he doesn't take your money and become a financial burden on your life\n",
            "Reminds me of \"It's your city!\" back in The Flash 2X08.\n",
            "he was stellar the Memphis game down the stretch. honestly forgot about that\n",
            "Yep just googled it and she‚Äôs freezing her eggs and telling EVERYONE how I missed this...who knows\n",
            "I didn‚Äôt know they ventured outside Facebook\n",
            "He was only thrown in there so we could have [NAME] get heroically saved by him and so we would hate [NAME]\n",
            "Henlo little alligatrr. ou almost slipped there. OH FUK NO NO NO NO ALIGATRR PLZ DONT EET MEEEEEEEE\n",
            "The irony of the photo is that 60% of university admissions are women\n",
            "I try to keep my hands busy. I would do better when I have acrylic nails because it wasn‚Äôt as easy/just wasn‚Äôt the same.\n",
            "Before things like that can happen we need to first atleast make it stable and usable for the people that actually do pay\n",
            "Justified or not he'll probably go before [NAME]\n",
            "29 and 39. Didn‚Äôt get to see my fathers parents for too long. I definitely got my condition from my Father.\n",
            "I once heard the rotting carcass of a trash Panda works also thats if you cant get your hands on a fresh chinchilla\n",
            "Apparently my state üòî\n",
            "He doesn't realize she's banging the ukulele guy.\n",
            "[NAME] might actually be able to pick her up and carry her without huffing and puffing now? üò≥üòì\n",
            "Don‚Äôt you just hate when they deforest the Sahara desert?\n",
            "----------------------------------------------------------------------\n",
            "True Label:  neutral   ||   Pred label:  annoyance   ||   Count:  23\n",
            "Papa Johns in my area basically gives away their pizza. I can smell the desperation in the store\n",
            "So she spat in the face of [NAME], nature and you by violating your health.\n",
            "I hid there just about everytime. Was often the person complaining about, \"stop dying\", and, \"hide BEFORE he hits 4 meat\".\n",
            "Verisimilitude, which here means, utter bs meant to help justify terrible favouritism.\n",
            "Everyone knows the good [NAME] are the dirty little devil's\n",
            "You conveniently aren't speaking to my assertion.\n",
            "would be US Biggest error ever\n",
            "ATTACH THE STONE OF TRIUMPH!!\n",
            "he's being immature\n",
            "Damned if nobody knows who they are, damned if they do\n",
            "From your username and the fact that you had to type that you‚Äôre NOT underage: now feels like you are\n",
            "Women are more neurotic.\n",
            "Your repeated need to retreat into victimhood is a snooze.\n",
            "Folks are complaining about the new buses.\n",
            "No justice with a cop's bullet in your head\n",
            "And motherf'ing crack!\n",
            "Just wait till they see what British capitalists have in store for them now we got \"arr soverinity\" back\n",
            "Tell her boyfriend and send him the screenshots of her saying she‚Äôs having affairs for proof. Then cut this toxic person out of your life!\n",
            "Why can‚Äôt we do both, approve wall funding and more border agents now and stop holding 800k federal workers hostage. \n",
            "[NAME] is a damn fool. No wonder his ex-wife is his boss and his babysitter.\n",
            "He‚Äôa establishment trash. I despise [NAME].\n",
            "Attempted years ago. Blocked by crooked politicians in bed with InBev and big beer. Gross.\n",
            "I just spent the whole week sneaking away to smoke, and trying to get into some girls shorts. \n",
            "----------------------------------------------------------------------\n",
            "True Label:  neutral   ||   Pred label:  admiration   ||   Count:  11\n",
            "Hes a daywalker!\n",
            "[NAME] was actually asked whether he‚Äôs peaked by a Philly sportswriter last season. His response was pretty interesting:\n",
            "I'll take PVZ. Your flair: \"Maybe necks time\"\n",
            "This. It IS a minority here, but they are very vocal and very active, exactly what you would expect from a PR team\n",
            "Best form of government is 150 people tribe in a situation where there are no non-perishable goods, just food an clothes. \n",
            "Those Boys risked their lives for a strong independent woman.\n",
            "There are far more bad ones than good ones. Stepparents that treat their stepchildren as their own are noteworthy for a reason.\n",
            "I was a [NAME] fan for a good bit, so that swayed me a little towards his teams\n",
            "here's a nice little introduction video for\n",
            "His best season was a luck filled one. He'd be nothing more than what [NAME] and [NAME] already offer but with worse defense and a worse bat.\n",
            "Big and smooth as a marble.\n",
            "----------------------------------------------------------------------\n",
            "True Label:  neutral   ||   Pred label:  curiosity   ||   Count:  16\n",
            "They seceded because [NAME] was elected despite not appearing on any slave owning states. How is this anything but under representation of ideology.\n",
            "It looks like how [NAME] is introducing the comedians in \"Whose line is it anyway ?\"\n",
            "And big boobs! Like, what?\n",
            "You always choose mum bro. What are you thinking\n",
            "From super smash bros melee?\n",
            "WHAT!?\n",
            "Have you pulled an updated Batch Guidance sheet? If your tossing a lot of coffee out, it sounds like you might be brewing too much.\n",
            "air supply? the irony of life\n",
            "You know even when women wear their hair natural they‚Äôre still putting products in it right?\n",
            "[NAME], this is your MLA, right? Dude *does* seem like a plug. \n",
            "[NAME]? never met one those.\n",
            "Thought this was r/monkeyspaw for a sec. Mind if I grant your wish anyway?\n",
            "Which one?\n",
            "If only they were more like [RELIGION] amirite?\n",
            "Can you imagine being the person in this costume #mascotlivesmatter\n",
            "Does everyones dad/grandpa have this exact one? Mine do.\n",
            "----------------------------------------------------------------------\n",
            "True Label:  curiosity   ||   Pred label:  anger   ||   Count:  13\n",
            "out of everyone why AC?\n",
            "Wait, you don't love reading people's blog posts on Reddit?\n",
            "You too huh?\n",
            "Was he transporting animals?\n",
            "The banana speaks! Do you just type one to three words in your comments or do you get an integer overflow if you go for four?\n",
            "Anyone else feel like [NAME] came dressed as [NAME]?\n",
            "Unlikely, but who knows? Memory speed rarely makes a difference in gaming, but I've seen stranger things. \n",
            "You really dont have a day off do you\n",
            "What reason do you have for not already having been prepared?\n",
            "Care to share your thought process ?\n",
            "Your girlfriend accepts gifts in exchange for sex? I got news for you homie...\n",
            "DID YOU KNOW THAT CASHEWS COME FROM A FRUIT!?!?\n",
            "How old are you?\n",
            "----------------------------------------------------------------------\n",
            "True Label:  approval   ||   Pred label:  anger   ||   Count:  11\n",
            "Yeah, that changes everything.\n",
            "Truth. If he had time for another relationship, he has time to pay for it. \n",
            "They've provided plenty of evidence that you have only supported so far.\n",
            "36 and definitely not what I used to be... still ok though!!!\n",
            "Well duh. The Chinese government control all Chinese language media in New Zealand. That's a fact.\n",
            "The Ethical code of conduct. However it's subjective in many instances. But its based on impairment\n",
            "I did and found it basically the same except I was getting drunk very easily.\n",
            "Same here. I had a lot of swelling but not abnormal pain.\n",
            "He was a US Attorney and Mayor of NYC. He's not an idiot and knows exactly what he's doing.\n",
            "Come on really. I‚Äôm for gay rights.\n",
            "I don‚Äôt know about romance, but I can certainly speak for the [NAME]\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1-yVvZN_d6x"
      },
      "source": [
        "## Table 1 in report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZubRSVI_g2Z"
      },
      "source": [
        "Result of the LAA model with CB loss, averaged over 10 experiments with different seeds. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69DhCE8mtkZ6",
        "outputId": "61f62f66-10e6-42b5-fede-bf283127a224"
      },
      "source": [
        "import json as js\n",
        "with open(\"out/seed1/output.json\") as o1:\n",
        "  out1 = js.load(o1)\n",
        "with open(\"out/seed10/output.json\") as o2:\n",
        "  out2 = js.load(o2)\n",
        "with open(\"out/seed20/output.json\") as o3:\n",
        "  out3 = js.load(o3)\n",
        "with open(\"out/seed42/output.json\") as o4:\n",
        "  out4 = js.load(o4)\n",
        "with open(\"out/seed72/output.json\") as o5:\n",
        "  out5 = js.load(o5)\n",
        "with open(\"out/seed711/output.json\") as o6:\n",
        "  out6 = js.load(o6)\n",
        "with open(\"out/seed142/output.json\") as o7:\n",
        "  out7 = js.load(o7)\n",
        "with open(\"out/seed355/output.json\") as o8:\n",
        "  out8 = js.load(o8)\n",
        "with open(\"out/seed151/output.json\") as o9:\n",
        "  out9 = js.load(o9)\n",
        "with open(\"out/seed400/output.json\") as o10:\n",
        "  out10 = js.load(o10)\n",
        "def avg_output(out1, out2, out3, out4, out5, out6,out7, out8, out9, out10, emotions):\n",
        "  result = dict()\n",
        "  for key in out1:\n",
        "    result[key] = (out1[key] + out2[key] + out3[key] + out4[key] + out5[key] + \n",
        "                  out6[key] + out7[key] + out8[key] + out9[key] + out10[key]) / 10\n",
        "    if key == \"macro_f1\": \n",
        "      # print(.1 * (out1[key]**2 + out2[key]**2 + out3[key]**2 + out4[key]**2 + out5[key]**2 + \n",
        "      #             out6[key]**2 + out7[key]**2 + out8[key]**2 + out9[key]**2 + out10[key]**2)- result[key]**2)\n",
        "      a = [out1[key] , out2[key] , out3[key] , out4[key] , out5[key] ,out6[key] , out7[key] , out8[key] , out9[key] , out10[key]]\n",
        "      print(np.std(a))\n",
        "  print(\"macro_f1: \", end=\" \")\n",
        "  print(result[\"macro_f1\"])\n",
        "  for emo in emotions:\n",
        "    key = emo + \"_f1\"\n",
        "    print(emo, end =\": \")\n",
        "    print(\"{:.2f}\".format(result[key]))\n",
        "\n",
        "avg_output(out1, out2, out3, out4, out5, out6, out7, out8, out9, out10, emotions)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.005141221898328572\n",
            "macro_f1:  0.5197420240793031\n",
            "admiration: 0.67\n",
            "amusement: 0.81\n",
            "anger: 0.49\n",
            "annoyance: 0.37\n",
            "approval: 0.41\n",
            "caring: 0.43\n",
            "confusion: 0.42\n",
            "curiosity: 0.56\n",
            "desire: 0.49\n",
            "disappointment: 0.33\n",
            "disapproval: 0.41\n",
            "disgust: 0.48\n",
            "embarrassment: 0.45\n",
            "excitement: 0.41\n",
            "fear: 0.67\n",
            "gratitude: 0.90\n",
            "grief: 0.42\n",
            "joy: 0.60\n",
            "love: 0.79\n",
            "nervousness: 0.34\n",
            "optimism: 0.56\n",
            "pride: 0.49\n",
            "realization: 0.26\n",
            "relief: 0.36\n",
            "remorse: 0.68\n",
            "sadness: 0.53\n",
            "surprise: 0.54\n",
            "neutral: 0.67\n"
          ]
        }
      ]
    }
  ]
}